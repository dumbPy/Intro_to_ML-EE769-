{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hiino7HiyD8w"
   },
   "source": [
    "\n",
    "# Google Landmark Recognition Challenge\n",
    "\n",
    "### by-\n",
    "   ### Sufiyan Adhikari (173190009)\n",
    "   ### Jaswant Singh    (173190020)\n",
    "   ### Khyati Thakkar   (173194001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4156,
     "status": "ok",
     "timestamp": 1525074838486,
     "user": {
      "displayName": "Sufiyan Adhikari",
      "photoUrl": "//lh3.googleusercontent.com/-5v7VMxmmv1Q/AAAAAAAAAAI/AAAAAAAAAWE/402P87Q3Mm8/s50-c-k-no/photo.jpg",
      "userId": "109884950391033451317"
     },
     "user_tz": -330
    },
    "id": "lZ2hxBSimgm0",
    "outputId": "c84bb975-a15f-401c-b178-e6fd476bd7a7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>http://static.panoramio.com/photos/original/70...</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6b2bb500b6a38aa0</td>\n",
       "      <td>http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...</td>\n",
       "      <td>11284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b399f09dee9c3c67</td>\n",
       "      <td>https://lh3.googleusercontent.com/-LOW2cjAqubA...</td>\n",
       "      <td>8429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19ace29d77a5be66</td>\n",
       "      <td>https://lh5.googleusercontent.com/-tnmSXwQcWL8...</td>\n",
       "      <td>6231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  cacf8152e2d2ae60  http://static.panoramio.com/photos/original/70...   \n",
       "1  0a58358a2afd3e4e  http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...   \n",
       "2  6b2bb500b6a38aa0  http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...   \n",
       "3  b399f09dee9c3c67  https://lh3.googleusercontent.com/-LOW2cjAqubA...   \n",
       "4  19ace29d77a5be66  https://lh5.googleusercontent.com/-tnmSXwQcWL8...   \n",
       "\n",
       "   landmark_id  \n",
       "0         4676  \n",
       "1         6651  \n",
       "2        11284  \n",
       "3         8429  \n",
       "4         6231  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vIpvUwBrspFG"
   },
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Y3NtqpjnmXa"
   },
   "source": [
    "### Data Sampling\n",
    "\n",
    "As Data size is Huge and Data is [Highly Skewed](https://www.kaggle.com/codename007/a-very-extensive-landmark-exploratory-analysis),  \n",
    "Sampling was required to make sure everything works before training on whole data.\n",
    "\n",
    "train: 336 GB with 1,220,165 images \n",
    "test: 34.9 GB with 116,163 images\n",
    "\n",
    "Data was downloaded [with]() this script, reducing the resolution to *299* from *1600*\n",
    "as demonstrated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 1177,
     "status": "ok",
     "timestamp": 1525077981271,
     "user": {
      "displayName": "Sufiyan Adhikari",
      "photoUrl": "//lh3.googleusercontent.com/-5v7VMxmmv1Q/AAAAAAAAAAI/AAAAAAAAAWE/402P87Q3Mm8/s50-c-k-no/photo.jpg",
      "userId": "109884950391033451317"
     },
     "user_tz": -330
    },
    "id": "iYaHFEzCrqaK",
    "outputId": "a7ba3274-5401-4656-b677-f87844aaf0a3",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmark IDs with Very Few Photos: \n",
      "\n",
      "   Photos  Id Count\n",
      "0       1       159\n",
      "1       2       291\n",
      "2       3       631\n",
      "3       4       999\n",
      "4       5      1314\n",
      "\n",
      "\n",
      "Landmarks IDs with Very High Number of Photos \n",
      "\n",
      "     Photos  Id Count\n",
      "759   13271         1\n",
      "760   18471         1\n",
      "761   23415         1\n",
      "762   50148         1\n",
      "763   50337         1\n"
     ]
    }
   ],
   "source": [
    "def show_count(train):\n",
    "    temp = pd.DataFrame(train.landmark_id.value_counts())\n",
    "    temp.reset_index(inplace=True)\n",
    "    temp.columns = ['landmark_id','count1']\n",
    "    temp = pd.DataFrame(temp.count1.value_counts())\n",
    "    temp = temp.sort_index()\n",
    "    temp.reset_index(inplace=True)\n",
    "    temp.columns = [\"Photos\",\"Id Count\"]\n",
    "    print(\"Landmark IDs with Very Few Photos: \\n\")\n",
    "    print(temp.head())\n",
    "    print(\"\\n\\nLandmarks IDs with Very High Number of Photos \\n\")\n",
    "    print(temp.tail())\n",
    "show_count(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_data  sample_submission.csv  test.csv  train_100\tvalid\r\n",
      "models\t    temp_1\t\t   tmp\t     train_40\r\n",
      "planet\t    test\t\t   train     train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Td0TFnOxr88B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getenv(\"HOME\")\n",
    "os.chdir(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rhaZXPo3nIic"
   },
   "source": [
    "### Reducing Train Data and Extracting Validation Data\n",
    "As we can see above, 159 Landmark IDs have only 1 photo, 259 have only 2 photos, etc.\n",
    "where as, a few IDs have photos in excess of several thousand.\n",
    "The Below function was written to take in the original train.csv file and reduce it to include maximum *trn_sz* photos of each landmark for training, and also generate maximum *val_sz* of validation photo indexes of each landmark if it has more than *trn*sz* photos and save it in a python list as required by **fastai** library\n",
    "\n",
    "It Dumps these into a pickle file with name train_val_<trn_sz>_<val_sz>.pkl\n",
    "\n",
    "and can be imported as *train, val_idxs = joblib.load(filename)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing_in_train = []\n",
    "for i, row in train.iterrows():\n",
    "    filename = f'{HOME}/data/train/{row[\"id\"]}.jpg'\n",
    "    if not os.path.exists(filename): \n",
    "        missing_in_train.append(i)\n",
    "    elif 0 == os.path.getsize(filename):\n",
    "        #Deleting the empty files\n",
    "        os.unlink(filename)\n",
    "        missing_in_train.append(i)\n",
    "print(\"Number of Photos Not Downloaded: \", len(missing_in_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.chdir(HOME)\n",
    "train.drop(index=missing_in_train, inplace=True)\n",
    "train.to_csv(\"data/train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Training Data Size:  (1225029, 3)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"data\")\n",
    "train_data = pd.read_csv('train.csv')\n",
    "print(\"Actual Training Data Size: \",train_data.shape)\n",
    "temp=pd.DataFrame(train_data.landmark_id.value_counts())\n",
    "temp.reset_index(inplace=True)\n",
    "temp.columns = ['landmark_id','count']\n",
    "os.chdir(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Training Data Size:  (1225029, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9633</td>\n",
       "      <td>50337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6051</td>\n",
       "      <td>50148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6599</td>\n",
       "      <td>23415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9779</td>\n",
       "      <td>18471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2061</td>\n",
       "      <td>13271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   landmark_id  count\n",
       "0         9633  50337\n",
       "1         6051  50148\n",
       "2         6599  23415\n",
       "3         9779  18471\n",
       "4         2061  13271"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "print(\"Actual Training Data Size: \",train_data.shape)\n",
    "temp=pd.DataFrame(train_data.landmark_id.value_counts())\n",
    "temp.reset_index(inplace=True)\n",
    "temp.columns = ['landmark_id','count']\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>http://static.panoramio.com/photos/original/70...</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6b2bb500b6a38aa0</td>\n",
       "      <td>http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...</td>\n",
       "      <td>11284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b399f09dee9c3c67</td>\n",
       "      <td>https://lh3.googleusercontent.com/-LOW2cjAqubA...</td>\n",
       "      <td>8429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19ace29d77a5be66</td>\n",
       "      <td>https://lh5.googleusercontent.com/-tnmSXwQcWL8...</td>\n",
       "      <td>6231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  cacf8152e2d2ae60  http://static.panoramio.com/photos/original/70...   \n",
       "1  0a58358a2afd3e4e  http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...   \n",
       "2  6b2bb500b6a38aa0  http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...   \n",
       "3  b399f09dee9c3c67  https://lh3.googleusercontent.com/-LOW2cjAqubA...   \n",
       "4  19ace29d77a5be66  https://lh5.googleusercontent.com/-tnmSXwQcWL8...   \n",
       "\n",
       "   landmark_id  \n",
       "0         4676  \n",
       "1         6651  \n",
       "2        11284  \n",
       "3         8429  \n",
       "4         6231  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To add fastai to system path\n",
    "import sys\n",
    "sys.path.append(f'{HOME}/fastai')\n",
    "\n",
    "\n",
    "\n",
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "\n",
    "PATH = f'{HOME}/data/'\n",
    "sz=64\n",
    "arch = resnet34\n",
    "bs=64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(f'{PATH}train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18563/18563 [38:23<00:00,  8.06it/s]\n",
      "100%|██████████| 155/155 [00:19<00:00,  7.78it/s]\n"
     ]
    }
   ],
   "source": [
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs, num_workers=8)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True, ps=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5466eda2524ed18d42fcd13c966f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 14828/18563 [10:29<02:38, 23.56it/s, loss=23.1]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrf=learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45e197f1b06401f96a1292058e77c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 434/18563 [00:07<05:27, 55.33it/s, loss=8.35]\n",
      "epoch      trn_loss   val_loss   accuracy                       \n",
      "    0      4.990365   11.734937  0.000101  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([11.73494]), 0.00010082677959265981]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "learn.save(f'model_{sz}_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7b44afa0b143acb348779269f70b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                       \n",
      "    0      4.84581    12.167926  0.000101  \n",
      "    1      4.616157   12.441432  0.000101                       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.precompute=False\n",
    "learn.fit(lr, 2, cycle_len=1)\n",
    "learn.save(f'model_{sz}_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### OverFitting Model\n",
    "We can see from above that the model is overfitting.\n",
    "This is probably due to some landmarks have a lot more photos that the others.\n",
    "Skewed Dataset needs to be handelled.\n",
    "Our Solution:\n",
    "Limiting max photos of each landmark to 30\n",
    "Creating *hard links* of photos if photos of a landmark are below 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "HOME=os.getenv(\"HOME\")\n",
    "PATH = f'{HOME}/data'\n",
    "TRAIN = f'{PATH}/train'\n",
    "EXTRA = f'{PATH}/extra'\n",
    "dir_list = os.listdir(f'{PATH}/train')\n",
    "for some_dir in dir_list:\n",
    "    files = os.listdir(f'{PATH}/train/{some_dir}')\n",
    "    if len(files)>30:\n",
    "        for file in files[30:]:\n",
    "            os.renames(f'{TRAIN}/{some_dir}/{file}', f'{EXTRA}/{some_dir}/{file}')\n",
    "    elif len(files)<30:\n",
    "        count=len(files)\n",
    "        while count <30:\n",
    "            for file in files:\n",
    "                if count<30:  \n",
    "                    os.link(f'{TRAIN}/{some_dir}/{file}', \n",
    "                        f\"{TRAIN}/{some_dir}/{'%020x' % random.randrange(16**20)}.jpg\")\n",
    "                    count+=1\n",
    "print(\"Done Setting Data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e639b144bc4592a3bf1564035f01da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                         \n",
      "    0      2.731841   14.086988  0.000202  \n",
      "    1      2.250377   15.120018  0.000202                         \n",
      " 39%|███▉      | 7328/18563 [25:47<39:33,  4.73it/s, loss=2.23]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3c256429f180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'model_{sz}_3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "lr=np.array([lr/9,lr/3,lr])\n",
    "learn.fit(lr, 3, cycle_len=1)\n",
    "learn.save(f'model_{sz}_3')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gX4qAYJLoBs8",
    "XNs7zY9APqfI",
    "H7Y97zTktxOY",
    "SBzhGAububOJ"
   ],
   "default_view": {},
   "name": "Landmark_Recog.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
