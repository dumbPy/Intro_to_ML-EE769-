{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hiino7HiyD8w"
   },
   "source": [
    "\n",
    "# Google Landmark Recognition Challenge\n",
    "\n",
    "### by-\n",
    "   ### Sufiyan Adhikari (173190009)\n",
    "   ### Jaswant Singh    (173190020)\n",
    "   ### Khyati Thakkar   (173194001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4156,
     "status": "ok",
     "timestamp": 1525074838486,
     "user": {
      "displayName": "Sufiyan Adhikari",
      "photoUrl": "//lh3.googleusercontent.com/-5v7VMxmmv1Q/AAAAAAAAAAI/AAAAAAAAAWE/402P87Q3Mm8/s50-c-k-no/photo.jpg",
      "userId": "109884950391033451317"
     },
     "user_tz": -330
    },
    "id": "lZ2hxBSimgm0",
    "outputId": "c84bb975-a15f-401c-b178-e6fd476bd7a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>http://static.panoramio.com/photos/original/70...</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6b2bb500b6a38aa0</td>\n",
       "      <td>http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...</td>\n",
       "      <td>11284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b399f09dee9c3c67</td>\n",
       "      <td>https://lh3.googleusercontent.com/-LOW2cjAqubA...</td>\n",
       "      <td>8429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19ace29d77a5be66</td>\n",
       "      <td>https://lh5.googleusercontent.com/-tnmSXwQcWL8...</td>\n",
       "      <td>6231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  cacf8152e2d2ae60  http://static.panoramio.com/photos/original/70...   \n",
       "1  0a58358a2afd3e4e  http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...   \n",
       "2  6b2bb500b6a38aa0  http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...   \n",
       "3  b399f09dee9c3c67  https://lh3.googleusercontent.com/-LOW2cjAqubA...   \n",
       "4  19ace29d77a5be66  https://lh5.googleusercontent.com/-tnmSXwQcWL8...   \n",
       "\n",
       "   landmark_id  \n",
       "0         4676  \n",
       "1         6651  \n",
       "2        11284  \n",
       "3         8429  \n",
       "4         6231  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vIpvUwBrspFG"
   },
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Y3NtqpjnmXa"
   },
   "source": [
    "### Data Sampling\n",
    "\n",
    "As Data size is Huge and Data is [Highly Skewed](https://www.kaggle.com/codename007/a-very-extensive-landmark-exploratory-analysis),  \n",
    "Sampling was required to make sure everything works before training on whole data.\n",
    "\n",
    "train: 336 GB with 1,220,165 images \n",
    "test: 34.9 GB with 116,163 images\n",
    "\n",
    "Data was downloaded [with]() this script, reducing the resolution to *299* from *1600*\n",
    "as demonstrated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1177,
     "status": "ok",
     "timestamp": 1525077981271,
     "user": {
      "displayName": "Sufiyan Adhikari",
      "photoUrl": "//lh3.googleusercontent.com/-5v7VMxmmv1Q/AAAAAAAAAAI/AAAAAAAAAWE/402P87Q3Mm8/s50-c-k-no/photo.jpg",
      "userId": "109884950391033451317"
     },
     "user_tz": -330
    },
    "id": "iYaHFEzCrqaK",
    "outputId": "a7ba3274-5401-4656-b677-f87844aaf0a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmark IDs with Very Few Photos: \n",
      "\n",
      "   Photos  Id Count\n",
      "0       1       164\n",
      "1       2       303\n",
      "2       3       632\n",
      "3       4      1022\n",
      "4       5      1308\n",
      "\n",
      "\n",
      "Landmarks IDs with Very High Number of Photos \n",
      "\n",
      "     Photos  Id Count\n",
      "774   13208         1\n",
      "775   18328         1\n",
      "776   23261         1\n",
      "777   49880         1\n",
      "778   50079         1\n"
     ]
    }
   ],
   "source": [
    "def show_count(train):\n",
    "    temp = pd.DataFrame(train.landmark_id.value_counts())\n",
    "    temp.reset_index(inplace=True)\n",
    "    temp.columns = ['landmark_id','count1']\n",
    "    temp = pd.DataFrame(temp.count1.value_counts())\n",
    "    temp = temp.sort_index()\n",
    "    temp.reset_index(inplace=True)\n",
    "    temp.columns = [\"Photos\",\"Id Count\"]\n",
    "    print(\"Landmark IDs with Very Few Photos: \\n\")\n",
    "    print(temp.head())\n",
    "    print(\"\\n\\nLandmarks IDs with Very High Number of Photos \\n\")\n",
    "    print(temp.tail())\n",
    "show_count(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models\t\t       train\t       train_30_4.csv  train_40.csv\r\n",
      "planet\t\t       train_100       train_30_5.csv  train.csv\r\n",
      "sample_submission.csv  train_100.csv   train_30_6.csv  train_val_100_10.pkl\r\n",
      "temp_1\t\t       train_30_0.csv  train_30_7.csv  train_val_30_10.pkl\r\n",
      "test\t\t       train_30_1.csv  train_30_8.csv  train_val_30_5.pkl\r\n",
      "test.csv\t       train_30_2.csv  train_30.csv    train_val_40_10.pkl\r\n",
      "tmp\t\t       train_30_3.csv  train_40\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Td0TFnOxr88B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getenv(\"HOME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rhaZXPo3nIic"
   },
   "source": [
    "### Reducing Train Data and Extracting Validation Data\n",
    "As we can see above, 159 Landmark IDs have only 1 photo, 259 have only 2 photos, etc.\n",
    "where as, a few IDs have photos in excess of several thousand.\n",
    "The Below function was written to take in the original train.csv file and reduce it to include maximum *trn_sz* photos of each landmark for training, and also generate maximum *val_sz* of validation photo indexes of each landmark if it has more than *trn*sz* photos and save it in a python list as required by **fastai** library\n",
    "\n",
    "It Dumps these into a pickle file with name train_val_<trn_sz>_<val_sz>.pkl\n",
    "\n",
    "and can be imported as *train, val_idxs = joblib.load(filename)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "missing_in_train = []\n",
    "for i, row in train.iterrows():\n",
    "    filename = f'{HOME}/data/train/{row[\"id\"]}.jpg'\n",
    "    if not os.path.exists(filename): \n",
    "        missing_in_train.append(i)\n",
    "    elif 0 == os.path.getsize(filename):\n",
    "        #Deleting the empty files\n",
    "        os.unlink(filename)\n",
    "        missing_in_train.append(i)\n",
    "print(\"Number of Photos Not Downloaded: \", len(missing_in_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.chdir(HOME)\n",
    "train.drop(index=missing_in_train, inplace=True)\n",
    "train.to_csv(\"data/train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val_set(trn_sz=None, val_sz=5):\n",
    "    if trn_sz==None:\n",
    "        print(\"Train Size Not given. Exiting Train Set Generation!!!\")        \n",
    "        return()        \n",
    "\n",
    "    import os\n",
    "    import numpy as np \n",
    "    import pandas as pd\n",
    "    from sklearn.externals import joblib #used for pickle file handeling    \n",
    "    cur_dir=os.getcwd()\n",
    "    os.chdir(f'{HOME}/data')    \n",
    "    filename=f'train_val_{trn_sz}_{val_sz}.pkl'\n",
    "    if os.path.exists(filename):\n",
    "        print(f'Train and Validation Data with trn_sz={trn_sz}, val_sz={val_sz} already exists:')\n",
    "        return()\n",
    "    train = pd.read_csv('train.csv')\n",
    "    print(\"Actual Training Data Size: \",train_data.shape)\n",
    "    max_count=dict(train_data.landmark_id.value_counts())\n",
    "    keys = max_count.keys()\n",
    "    \n",
    "    new_train=[]\n",
    "    counter_dict = {}\n",
    "    for key in keys: counter_dict[key] = 0\n",
    "    #Validation Set is only defined as indexes of train.csv\n",
    "    val_idxs=[]\n",
    "    for i, row in train.iterrows():\n",
    "        key = row['landmark_id']\n",
    "        if counter_dict[key] < trn_sz:\n",
    "            new_train.append(row.values)\n",
    "            counter_dict[key] = counter_dict[key]+1\n",
    "        elif counter_dict[key] < trn_sz+val_sz:\n",
    "            new_train.append(row.values)\n",
    "            counter_dict[key] = counter_dict[key]+1\n",
    "            val_idxs.append(len(new_train)-1)\n",
    "    new_train = pd.DataFrame(new_train, columns = train.columns)\n",
    "    new_train.drop('url', inplace=True, axis=1)\n",
    "    new_train.to_csv(f'train_{trn_sz}.csv', index=False)   \n",
    "    filename=f'train_val_{trn_sz}_{val_sz}.pkl'\n",
    "    joblib.dump((new_train, val_idxs), filename)\n",
    "    print(f'Train Dataframe and Val_idxs dumped to {filename}')\n",
    "    print(f'Train Data also saved to train_{trn_sz}.csv')\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Training Data Size:  (1217714, 3)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"data\")\n",
    "train_data = pd.read_csv('train.csv')\n",
    "print(\"Actual Training Data Size: \",train_data.shape)\n",
    "temp=pd.DataFrame(train_data.landmark_id.value_counts())\n",
    "temp.reset_index(inplace=True)\n",
    "temp.columns = ['landmark_id','count']\n",
    "os.chdir(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 1, 1: 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame([[1, 2], [3, 4]], columns=['f', 's'])\n",
    "dict(a.f.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Training Data Size:  (1217714, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9633</td>\n",
       "      <td>50079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6051</td>\n",
       "      <td>49880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6599</td>\n",
       "      <td>23261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9779</td>\n",
       "      <td>18328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2061</td>\n",
       "      <td>13208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   landmark_id  count\n",
       "0         9633  50079\n",
       "1         6051  49880\n",
       "2         6599  23261\n",
       "3         9779  18328\n",
       "4         2061  13208"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "print(\"Actual Training Data Size: \",train_data.shape)\n",
    "temp=pd.DataFrame(train_data.landmark_id.value_counts())\n",
    "temp.reset_index(inplace=True)\n",
    "temp.columns = ['landmark_id','count']\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>http://static.panoramio.com/photos/original/70...</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6b2bb500b6a38aa0</td>\n",
       "      <td>http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...</td>\n",
       "      <td>11284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b399f09dee9c3c67</td>\n",
       "      <td>https://lh3.googleusercontent.com/-LOW2cjAqubA...</td>\n",
       "      <td>8429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19ace29d77a5be66</td>\n",
       "      <td>https://lh5.googleusercontent.com/-tnmSXwQcWL8...</td>\n",
       "      <td>6231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                url  \\\n",
       "0  cacf8152e2d2ae60  http://static.panoramio.com/photos/original/70...   \n",
       "1  0a58358a2afd3e4e  http://lh6.ggpht.com/-igpT6wu0mIA/ROV8HnUuABI/...   \n",
       "2  6b2bb500b6a38aa0  http://lh6.ggpht.com/-vKr5G5MEusk/SR6r6SJi6mI/...   \n",
       "3  b399f09dee9c3c67  https://lh3.googleusercontent.com/-LOW2cjAqubA...   \n",
       "4  19ace29d77a5be66  https://lh5.googleusercontent.com/-tnmSXwQcWL8...   \n",
       "\n",
       "   landmark_id  \n",
       "0         4676  \n",
       "1         6651  \n",
       "2        11284  \n",
       "3         8429  \n",
       "4         6231  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sz = 40\n",
    "parts = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Validation Data with trn_sz=40, val_sz=10 already exists:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_train_val_set(trn_sz=trn_sz, val_sz=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(HOME)\n",
    "from sklearn.externals import joblib #used for pickle file handeling    \n",
    "train, val_idxs = joblib.load(\"data/train_val_30_10.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(HOME)\n",
    "train = pd.read_csv(f\"data/train_{trn_sz}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cacf8152e2d2ae60</td>\n",
       "      <td>4676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0a58358a2afd3e4e</td>\n",
       "      <td>6651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6b2bb500b6a38aa0</td>\n",
       "      <td>11284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b399f09dee9c3c67</td>\n",
       "      <td>8429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19ace29d77a5be66</td>\n",
       "      <td>6231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  landmark_id\n",
       "0  cacf8152e2d2ae60         4676\n",
       "1  0a58358a2afd3e4e         6651\n",
       "2  6b2bb500b6a38aa0        11284\n",
       "3  b399f09dee9c3c67         8429\n",
       "4  19ace29d77a5be66         6231"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the rows\n",
    "train = train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "temp = train.shape[0]-1\n",
    "sz_ls = [int(i*temp) for i in np.linspace(0, 1, num=parts ,endpoint=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"data/train_{trn_sz}\"):\n",
    "    os.mkdir(f\"data/train_{trn_sz}\")\n",
    "for i in range(len(sz_ls)-1):\n",
    "    train.iloc[sz_ls[i]:sz_ls[i+1], :].to_csv(f'data/train_{trn_sz}/train_{trn_sz}_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To add fastai to system path\n",
    "import sys\n",
    "sys.path.append(f'{HOME}/fastai')\n",
    "\n",
    "\n",
    "\n",
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "\n",
    "PATH = f'{HOME}/data'\n",
    "sz=64\n",
    "f_model = resnet34\n",
    "bs=36\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2445/2445 [03:25<00:00, 11.88it/s]\n",
      "100%|██████████| 612/612 [00:49<00:00, 12.46it/s]\n"
     ]
    }
   ],
   "source": [
    "#for i in range(3):\n",
    "os.chdir(f'{HOME}/data')\n",
    "i=0\n",
    "label_csv = f'{PATH}/train_{trn_sz}/train_{trn_sz}_{i}.csv'\n",
    "n = len(list(open(label_csv)))-1\n",
    "val_idxs = get_cv_idxs(n)\n",
    "tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "data = ImageClassifierData.from_csv(PATH, 'train', label_csv, bs=bs, tfms=tfms,\n",
    "                                    suffix='.jpg', val_idxs=val_idxs, test_name='test')\n",
    "learn = ConvLearner.pretrained(f_model, data, precompute=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e7b2b32aea4b82b3d67575e7df3f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 2110/2445 [00:29<00:04, 72.67it/s, loss=38.2]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrf=learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ee324df65648b584e5105017456c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2445 [00:00<02:32, 15.97it/s, loss=10.5]\n",
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      7.659976   7.147836   0.062182  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([7.14784]), 0.06218181942843578]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa6a2e6faee4632bcee8143c5eb420c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      7.616468   7.10036    0.063136  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b0f612c95148bc91e3ba5443b49ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      6.397636   6.180018   0.131182  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d1b36a88704b9a981d13aa36986911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      5.485837   5.76505    0.177182  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a4f66b40344aab84e0dfedaef5d29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      4.89109    5.572054   0.202045  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_data(i):\n",
    "    label_csv = f'{PATH}/train_{trn_sz}/train_{trn_sz}_{i}.csv'\n",
    "    n = len(list(open(label_csv)))-1\n",
    "    val_idxs = get_cv_idxs(n)\n",
    "    tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "    data = ImageClassifierData.from_csv(PATH, 'train', label_csv, bs=bs, tfms=tfms,\n",
    "                                        suffix='.jpg', val_idxs=val_idxs, test_name='test')\n",
    "    return (data)\n",
    "    \n",
    "learn = ConvLearner.pretrained(f_model, data, precompute=True)\n",
    "for i in range(parts):\n",
    "    learn.set_data(get_data(i))\n",
    "    learn.fit(lr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'model_{sz}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gX4qAYJLoBs8",
    "XNs7zY9APqfI",
    "H7Y97zTktxOY",
    "SBzhGAububOJ"
   ],
   "default_view": {},
   "name": "Landmark_Recog.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
